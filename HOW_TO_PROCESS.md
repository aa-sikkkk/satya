# ğŸš€ How to Process Textbooks & Notes

## âš¡ Quick Answer: One Command

```bash
python scripts/rag_data_preparation/process_all.py
```

**That's it!** This processes both textbooks and notes, generates embeddings, and adds everything to ChromaDB.

---

## ğŸ“‹ Detailed Instructions

### Prerequisites

1. **Add your PDFs:**
   - Textbooks â†’ `textbooks/grade_10/`
   - Notes â†’ `notes/grade_10/` (optional)

2. **Run the processing:**
   ```bash
   python scripts/rag_data_preparation/process_all.py
   ```

### What Happens

1. âœ… Processes all textbooks from `textbooks/grade_10/`
2. âœ… Processes all notes from `notes/grade_10/`
3. âœ… Creates optimized chunks (400 words each)
4. âœ… Extracts images
5. âœ… Generates embeddings
6. âœ… Adds to ChromaDB collections

### Processing Options

```bash
# Process everything (default)
python scripts/rag_data_preparation/process_all.py

# Only textbooks
python scripts/rag_data_preparation/process_all.py --textbooks-only

# Only notes
python scripts/rag_data_preparation/process_all.py --notes-only

# Process but skip embeddings (for testing)
python scripts/rag_data_preparation/process_all.py --skip-embeddings
```

---

## ğŸ“Š Verify Results

After processing, check what was created:

```bash
python -c "
from scripts.rag_data_preparation.embedding_generator import EmbeddingGenerator
gen = EmbeddingGenerator()
info = gen.get_collection_info()
print('\nğŸ“Š ChromaDB Collections:')
for name, data in sorted(info.items()):
    count = data.get('count', 0)
    print(f'  {name}: {count} chunks')
"
```

Expected output:
```
ğŸ“Š ChromaDB Collections:
  computer_science_grade_10: 1234 chunks
  computer_science_notes_grade_10: 567 chunks
  english_grade_10: 2345 chunks
  english_notes_grade_10: 890 chunks
  science_grade_10: 3456 chunks
  science_notes_grade_10: 1234 chunks
```

---

## ğŸ”„ Alternative: Process Separately

If you prefer to process books and notes separately:

### Textbooks Only
```bash
python scripts/rag_data_preparation/process_all.py --textbooks-only
```

### Notes Only
```bash
python scripts/rag_data_preparation/process_all.py --notes-only
```

---

## ğŸ”§ Advanced: Using Python API Directly

> **Note**: The `process_all.py` script is recommended for most users. Use the Python API only if you need custom processing logic.

If you need more control, you can use the Python API directly:

```python
from scripts.rag_data_preparation.pdf_processor import PDFProcessor
from scripts.rag_data_preparation.embedding_generator import EmbeddingGenerator

# Process textbooks
processor = PDFProcessor('processed_data_new')
processor.run_pipeline()

# Generate embeddings
generator = EmbeddingGenerator()
generator.populate_chromadb_with_content(include_notes=False)
```

---

## ğŸ“ File Structure

```
Satya/
â”œâ”€â”€ textbooks/grade_10/          # Your textbook PDFs here
â”‚   â”œâ”€â”€ computer_science_grade_10.pdf
â”‚   â”œâ”€â”€ english_grade_10.pdf
â”‚   â””â”€â”€ science_grade_10.pdf
â”‚
â”œâ”€â”€ notes/grade_10/               # Your notes PDFs here (optional)
â”‚   â”œâ”€â”€ computer_science_notes.pdf
â”‚   â”œâ”€â”€ english_notes.pdf
â”‚   â””â”€â”€ science_notes.pdf
â”‚
â””â”€â”€ processed_data_new/          # Generated after processing
    â”œâ”€â”€ chunks/                   # JSON chunk files
    â”œâ”€â”€ images/                   # Extracted images
    â””â”€â”€ reports/                  # Processing reports
```

---

## ğŸ†˜ Troubleshooting

### "No PDF files found"
- âœ… Check files are in correct folders: `textbooks/grade_10/` or `notes/grade_10/`
- âœ… Verify file extensions are `.pdf` (not `.PDF` or `.Pdf`)
- âœ… Check file permissions (readable)

### "Collection already exists"
- âœ… This is normal if re-processing
- âœ… Old chunks will be updated/added to
- âœ… Not an error - your data is safe

### "Failed to process PDF"
- âœ… Check PDF has extractable text (not just images)
- âœ… Scanned PDFs will use OCR automatically
- âœ… Check processing logs in `processed_data_new/logs/`
- âœ… Try a different PDF to test

### "ChromaDB not available"
- âœ… Install: `pip install chromadb`
- âœ… Check ChromaDB path: `satya_data/chroma_db/`

---

## ğŸ“š More Help

- **Quick Start**: `scripts/rag_data_preparation/QUICK_START.md`
- **Input Folders Guide**: `INPUT_FOLDERS_GUIDE.md`
- **Textbooks Guide**: `textbooks/README.md`
- **Notes Guide**: `notes/README.md`
- **Notes vs Books**: `scripts/rag_data_preparation/NOTES_GUIDE.md`

---

## âœ… Success Checklist

After running `process_all.py`, you should have:

- [ ] Processed chunks in `processed_data_new/chunks/`
- [ ] Extracted images in `processed_data_new/images/`
- [ ] ChromaDB collections created (check with `get_collection_info()`)
- [ ] Both books and notes searchable in RAG system

---

**That's it!** Your RAG system is now ready to use. ğŸ‰

